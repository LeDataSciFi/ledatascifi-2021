{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting the principles from last chapter into code\n",
    "\n",
    "1. All of your import functions\n",
    "2. Load data \n",
    "3. Split your data into 2 subsamples: a \"test\" and \"train\" portion as [in this page](03_ML) or [this page](03c_ModelEval) or [this page](03c1_OOS). This is the first arrow in the picture below. We will do all of our work on the \"train\" sample. \n",
    "<img src=\"img/feature_5_fold_cv.jpg\" alt=\"From DS100-1\" style=\"width:300px\">  \n",
    "4. Before modelling, do EDA (**on the training data only!**)\n",
    "    - Sample basics: What is the unit of observation? What time spans are covered?\n",
    "    - Look for outliers, missing values, or data errors\n",
    "    - Note what variables are continuous or discrete numbers, which variables are categorical variables (and whether the categorical ordering is meaningful)     \n",
    "    - You should read up on what all the variables mean from the documentation in the data folder.\n",
    "    - Visually explore the relationship between `v_Sale_Price` and other variables.\n",
    "        - For continuous variables - take note of whether the relationship seems linear or quadratic or polynomial\n",
    "        - For categorical variables - maybe try a box plot for the various levels?\n",
    "    - Now decide how you'd clean the data (imputing missing values, scaling variables, encoding categorical variables). These lessons will go into the preprocessing portion of your pipeline below. The [sklearn guide on preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html) is very informative!    \n",
    "5. Prepare to optimize a series of models \n",
    "    1. Set up one pipeline to clean each type of variable \n",
    "    2. Combine those pipes into \"preprocessing\" pipe using [ColumnTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer)\n",
    "    1. Set up your cross validation method:\n",
    "        - The picture above illustrates 5 folds apparently based on the row number.\n",
    "        - There are many [CV splitters](https://scikit-learn.org/stable/modules/classes.html#splitter-classes) available, including TimeSeriesSplit (a starting point for asset price predictions) and [GroupTimesSeriesSplit](https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243) is in development (which addresses a core problem with TimeSeriesSplit, and [is shown in practice here](https://www.kaggle.com/jorijnsmit/found-the-holy-grail-grouptimeseriessplit))\n",
    "    1. Set up your scoring [metric](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics) as discussed [here](03d_whatToMax)\n",
    "5. [Optimize candidate model 1](04d_optimizing_a_model) _on the training data_\n",
    "    1. Set up pipeline that combines preprocessing, estimator\n",
    "    1. Set up a hyper param grid\n",
    "    1. Find optimal hyper params (e.g. gridsearchcv)\n",
    "    1. Save pipeline with optimal params in place\n",
    "6. Repeat step 6 for other candidate models\n",
    "7. Compare all of the optimized models\n",
    "    ```python\n",
    "    # something like...\n",
    "    for model in models:\n",
    "        cross_validate(model, X, y,...)\n",
    "    ```\n",
    "\n",
    "---\n",
    "\n",
    "Here is that outline, but as a block of code you can use as a blueprint in projects:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import lots of functions\n",
    "# load data \n",
    "# split to test and train (link to split page/sk docs)\n",
    "\n",
    "## pre-modeling (on the training data only!)\n",
    "\n",
    "# do lots of EDA\n",
    "# look for missing values, which variables are what type, and outliers (copy from a6 prompt)\n",
    "# figure out how you'd clean the data (imputation, scaling, encoding categorical vars)\n",
    "# these lessons will go into the preprocessign portion of your pipeline \n",
    "\n",
    "## optimize a series of models \n",
    "\n",
    "# set up pipeline to clean each type of variable (1 pipe per var type)\n",
    "# combine those pipes into \"preprocess\" pipe\n",
    "# set up cv (can set up iterable to do OOS! or TimeSeriesSplit, or Snows(?))\n",
    "# set up scoring \n",
    "\n",
    "## optimize candidate model type #1: (link to optimizing one model page   04d_optimizing_a_model)\n",
    "\n",
    "#     set up pipeline (combines preprocessing, estimator)\n",
    "#     set up hyper param grid\n",
    "#     find optimal hyper params (e.g. gridsearchcv)\n",
    "#     save pipeline with optimal params in place\n",
    "#     (Note: you should spend time interrogating model predictions, plotting and printing\n",
    "#     does the model struggle predicting certain obs? excel at some?)\n",
    "\n",
    "## optimize candidate model type #2\n",
    "\n",
    "...\n",
    "\n",
    "## optimize candidate model type #N\n",
    "\n",
    "## compare the N optimized models\n",
    "\n",
    "# build list of models (each with own optimized hyperparams)\n",
    "# for model in models:\n",
    "#    cross_validate(model, X, y,...)\n",
    "# pick the winner!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
