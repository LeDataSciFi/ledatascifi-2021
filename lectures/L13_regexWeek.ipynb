{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Teaching notes go here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hello! Today\n",
    "\n",
    "- Where we are\n",
    "- Where we are going\n",
    "- But why go there?\n",
    "- Ok, I'm convinced, let's learn that...\n",
    "\n",
    "_I'm going to record, but remember participation credits_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Where were we...\n",
    "\n",
    "```python\n",
    "1. download_wiki_pages.py\n",
    "\n",
    "    1a. where am i going to put the files? create it.\n",
    "    1b. get a list of files (urls) to download\n",
    "    for each url in urls:\n",
    "        1c. download(url,to_some_place)\n",
    "        **4.3.2 and 4.3.3** will be very helpful\n",
    "        \n",
    "    1d. <don't push all these files to github! --> gitignore>    \n",
    "\n",
    "2. measure_risk.py\n",
    "\n",
    "3. analysis.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## download_wiki_pages.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from requests_html import HTMLSession # HTMLSession is how requests_html loads requests\n",
    "session = HTMLSession()\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
    "r = session.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Step 1: Get the URL to the S&P 500 firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "table = r.html.find('#constituents')[0]\n",
    "rows = table.find('tr')[1:]\n",
    "urls = []\n",
    "for row in rows:\n",
    "    a_url = list(row.find('td')[1].absolute_links)[0]\n",
    "    urls.append(a_url)\n",
    "#     grab the link in the second column?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Step 2: Download their wiki pages..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# the files go here:\n",
    "os.makedirs('text_files',exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def download(url,to_some_place):\n",
    "    # need to figure this out (4.3.2 and 4.3.3)\n",
    "\n",
    "for url in urls:\n",
    "    location = 'text_files/'+name of the firm...\n",
    "    # deciding on a text string for the location of the \n",
    "    # file is logic/planning/OS knowledge + using python strings\n",
    "    download(url,location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Where are we going this week?\n",
    "\n",
    "The main challenge: How can we \"create a risk variable\"?\n",
    "\n",
    "```python\n",
    "1. download_wiki_pages.py\n",
    "\n",
    "2. measure_risk.py\n",
    "    2a. create empty data, or load the wiki table\n",
    "    for each file in files:\n",
    "        2b. open file, create risk vars, add to dataset\n",
    "    2c. save dataset\n",
    "    \n",
    "3. analysis.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Strings\n",
    "\n",
    "- We have access to text files discussing the firms. \n",
    "- Those discussions are in a basic python object type called a string. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So you'll need to have a sense of working with strings.\n",
    "- And \"regex\" is how we will search those strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Data = power\n",
    "\n",
    "- New personal computers usually have 1TB+ of hard drive space\n",
    "- As of 2017, IBM estimated 2.5 MILLION TERABYTES of data were created everyday\n",
    "- Now: probably at least a billion more regular internet user\n",
    "    - Posts, texts, likes, searches, emails, location data\n",
    "    - 2020: 40 ZETTABYTES of web data (1ZB = 1billion TB = #stars are in the observable universe)\n",
    "    - 80% of that is unstructured text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## SO: Figuring out how to put structure on that text data is POWERFUL. \n",
    "\n",
    "- Google is one example\n",
    "- One common task: identifying topics in unstructured text (does the document discuss it at aOne very common task is identifying topics in unstructured text: Does the document discuss topic X?\n",
    "\n",
    "That's the #BigPicture of this 3 week section of class: \n",
    "- **3 seemingly \"too simple\" files = assignment 5\n",
    "- asgn 5 = most of the foundation for powerful analysis (easy to adapt and extend!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Again - the goal this week\n",
    "\n",
    "The main challenge: How can we \"create a risk variable\"?\n",
    "\n",
    "```python\n",
    "1. download_wiki_pages.py\n",
    "\n",
    "2. measure_risk.py\n",
    "    2a. create empty data, or load the wiki table\n",
    "    for each file in files:\n",
    "        2b. open file, create risk vars, add to dataset\n",
    "    2c. save dataset\n",
    "    \n",
    "3. analysis.py\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ok, \n",
    "\n",
    "1. Open this [2019 TSLA 10-K](https://www.sec.gov/Archives/edgar/data/1318605/000156459019003165/0001564590-19-003165.txt)\n",
    "2. **As a group:** Discuss how we can identify a topic in a text file**\n",
    "   - let's pick a topic as a class...\n",
    "   - read it to see if the firm discusses it and what you learn about (no/small/large exposure)\n",
    "   - Q1: how can we translate the way we looked for that risk in the document into steps/rules a computer can follow?\n",
    "   - Q2: how can we try to encode the \"size\" of exposure?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. Implementation via near_regex \n",
    "    - simple practice on TSLA\n",
    "    - simple practice on default strings\n",
    "    - try on a wiki page\n",
    "    - what do you need to know to improve the use of this function?\n",
    "        - some string and regex background (homework or next time? TBD)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Next class\n",
    "\n",
    "- Push our use of near_regex (string and regex games?)\n",
    "- Discuss conceptual issues with `measure_risk.py`\n",
    "- Discuss expectations for analysis file and the \"break\" week\n",
    "\n",
    "### Student demos \n",
    "- Task: Will be a continuation of something from today\n",
    "- Morning: Kristen (@KristenGong) and Sella (@sellalin)\n",
    "- Afternoon: Leo (@lpawlika) and Luke (@LukeRes21)\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary \n",
    "\n",
    "We covered\n",
    "- So much data!!! \n",
    "- One way to harness it (regex searches)\n",
    "\n",
    "![](https://media.giphy.com/media/H7x1H0veAJlo4/giphy.gif)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
